#!/usr/bin/env python
"""
Script de debugging para verificar si se est√° usando OpenAI o mocks
Ejecuta este script para ver qu√© est√° configurado en tu aplicaci√≥n
"""

import os
import sys
from pathlib import Path

# Agregar la ruta del proyecto al path
sys.path.insert(0, str(Path(__file__).parent))

from app.clients.llm_client import OpenAILLMClient
from app.services.ai_analysis_service import AIAnalysisService

print("=" * 80)
print("üîç DEBUGGING: Verificaci√≥n de configuraci√≥n de API")
print("=" * 80)
print()

# 1. Verificar variables de entorno
print("1Ô∏è‚É£  VARIABLES DE ENTORNO:")
print("-" * 80)

llm_api_key = os.getenv('LLM_API_KEY')
use_mock = os.getenv('USE_MOCK_RECOMMENDATIONS', 'false')
llm_model = os.getenv('LLM_MODEL', 'gpt-4o-mini')
llm_api_url = os.getenv('LLM_API_URL', 'https://api.openai.com/v1')

print(f"  LLM_API_KEY configurada: {'‚úÖ S√ç' if llm_api_key else '‚ùå NO'}")
if llm_api_key:
    # Mostrar solo los primeros y √∫ltimos caracteres por seguridad
    key_preview = f"{llm_api_key[:10]}...{llm_api_key[-10:]}"
    print(f"    Preview: {key_preview}")
else:
    print(f"    ‚ö†Ô∏è  No hay API key configurada. Se usar√°n MOCKS")

print(f"  USE_MOCK_RECOMMENDATIONS: {use_mock}")
print(f"  LLM_MODEL: {llm_model}")
print(f"  LLM_API_URL: {llm_api_url}")
print()

# 2. Verificar inicializaci√≥n del cliente OpenAI
print("2Ô∏è‚É£  INICIALIZACI√ìN DEL CLIENTE OPENAI:")
print("-" * 80)

try:
    client = OpenAILLMClient()
    print(f"  ‚úÖ Cliente inicializado correctamente")
    print(f"     - Modelo: {client.model}")
    print(f"     - URL: {client.base_url}")
    print(f"     - API Key presente: {'‚úÖ S√ç' if client.api_key else '‚ùå NO'}")
    print(f"     - Timeout: {client.timeout}s")
except Exception as e:
    print(f"  ‚ùå Error al inicializar cliente: {str(e)}")

print()

# 3. Verificar servicio de IA
print("3Ô∏è‚É£  INICIALIZACI√ìN DEL SERVICIO DE IA:")
print("-" * 80)

try:
    ai_service = AIAnalysisService()
    
    if ai_service.use_mock:
        print(f"  ‚ö†Ô∏è  USANDO SERVICIO SIMULADO (MOCK)")
        print(f"     Raz√≥n: ", end="")
        if use_mock == 'true':
            print("USE_MOCK_RECOMMENDATIONS=true")
        else:
            print("LLM_API_KEY no configurada")
    else:
        print(f"  ‚úÖ USANDO API DE OPENAI")
        print(f"     Modelo: {ai_service.llm_client.model}")
        
except Exception as e:
    print(f"  ‚ùå Error al inicializar servicio: {str(e)}")

print()
print("=" * 80)
print("üìã RECOMENDACIONES:")
print("=" * 80)

if not llm_api_key:
    print("""
  ‚ùå NO SE DETECT√ì API KEY DE OPENAI

  Para usar OpenAI en lugar de mocks, realiza uno de estos pasos:

  OPCI√ìN 1: Variable de entorno (recomendado)
  -------------------------------------------
  En PowerShell:
    $env:LLM_API_KEY = "tu-api-key-aqui"
    python run.py

  En Linux/Mac:
    export LLM_API_KEY="tu-api-key-aqui"
    python run.py

  OPCI√ìN 2: Archivo .env
  -----------------------
  Crea un archivo .env en el directorio ra√≠z con:
    LLM_API_KEY=tu-api-key-aqui
    LLM_MODEL=gpt-4o-mini
    LLM_API_URL=https://api.openai.com/v1

  OPCI√ìN 3: Dentro del c√≥digo
  ----------------------------
  Modifica app/clients/llm_client.py l√≠nea 51:
    self.api_key = "tu-api-key-aqui"
    
  ‚ö†Ô∏è  NO RECOMENDADO - ¬°Nunca hagas esto en producci√≥n!
    """)
elif use_mock == 'true':
    print("""
  ‚ö†Ô∏è  SE EST√Å USANDO MOCK EXPL√çCITAMENTE

  Para cambiar a OpenAI:
    - Elimina o cambia USE_MOCK_RECOMMENDATIONS=true
    - Aseg√∫rate de que LLM_API_KEY est√© configurada
    """)
else:
    print("""
  ‚úÖ CONFIGURACI√ìN CORRECTA - Usando OpenAI API
  
  El sistema est√° correctamente configurado para usar OpenAI.
  """)

print()
print("=" * 80)
